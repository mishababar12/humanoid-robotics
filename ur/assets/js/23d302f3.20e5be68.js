"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4150],{1055:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module4/outline","title":"Module 4 Outline: Vision-Language-Action (VLA)","description":"This document provides a detailed outline for Module 4 of the \\"Physical AI & Humanoid Robotics\\" textbook.","source":"@site/docs/module4/outline.md","sourceDirName":"module4","slug":"/module4/outline","permalink":"/humanoid-robotics/ur/docs/module4/outline","draft":false,"unlisted":false,"editUrl":"https://github.com/mishababar12/humanoid-robotics/tree/main/my-website/docs/module4/outline.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Module 4 Exercises","permalink":"/humanoid-robotics/ur/docs/module4/exercises"},"next":{"title":"ROS 2 for Robot Control","permalink":"/humanoid-robotics/ur/docs/category/ros-2-for-robot-control"}}');var t=i(4848),s=i(8453);const l={},r="Module 4 Outline: Vision-Language-Action (VLA)",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Key Topics",id:"key-topics",level:2},{value:"Practical Exercises",id:"practical-exercises",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"module-4-outline-vision-language-action-vla",children:"Module 4 Outline: Vision-Language-Action (VLA)"})}),"\n",(0,t.jsx)(n.p,{children:'This document provides a detailed outline for Module 4 of the "Physical AI & Humanoid Robotics" textbook.'}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Understand the concept of Vision-Language-Action (VLA) models."}),"\n",(0,t.jsx)(n.li,{children:"Learn how Large Language Models (LLMs) can be integrated into robotics."}),"\n",(0,t.jsx)(n.li,{children:"Understand the challenges and opportunities of human-robot interaction."}),"\n",(0,t.jsx)(n.li,{children:"Be able to build a simple VLA system that allows a robot to be controlled with natural language."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"key-topics",children:"Key Topics"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Introduction to Vision-Language-Action (VLA)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"What are VLAs?"}),"\n",(0,t.jsx)(n.li,{children:"The role of LLMs in robotics"}),"\n",(0,t.jsx)(n.li,{children:"Examples of VLA systems"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Integrating LLMs with Robotics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Using LLM APIs"}),"\n",(0,t.jsx)(n.li,{children:"Prompt engineering for robotics tasks"}),"\n",(0,t.jsx)(n.li,{children:"Connecting LLM outputs to robot actions"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Principles of HRI"}),"\n",(0,t.jsx)(n.li,{children:"Natural language as an interface for robots"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Building a Simple VLA System"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"System architecture"}),"\n",(0,t.jsx)(n.li,{children:"Integrating a pre-trained VLA model"}),"\n",(0,t.jsx)(n.li,{children:"Controlling a simulated robot with text commands"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"practical-exercises",children:"Practical Exercises"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Exercise 1: Using an LLM API to generate robot commands from natural language."}),"\n",(0,t.jsx)(n.li,{children:"Exercise 2: Building a simple text-based interface to control a simulated robot."}),"\n",(0,t.jsx)(n.li,{children:"Exercise 3: Integrating a simple VLA model to perform a pick-and-place task based on a text prompt."}),"\n",(0,t.jsx)(n.li,{children:"Exercise 4: Exploring the limitations and biases of LLMs in a robotics context."}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var o=i(6540);const t={},s=o.createContext(t);function l(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);