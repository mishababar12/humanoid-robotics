"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4868],{8009:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module4/exercises","title":"Module 4 Exercises","description":"These exercises are designed to accompany Module 4 of the \\"Physical AI & Humanoid Robotics\\" textbook.","source":"@site/docs/module4/exercises.md","sourceDirName":"module4","slug":"/module4/exercises","permalink":"/humanoid-robotics/docs/module4/exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/github/my-hackathone-project/tree/main/my-website/docs/module4/exercises.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/humanoid-robotics/docs/module4/"},"next":{"title":"Module 4 Outline: Vision-Language-Action (VLA)","permalink":"/humanoid-robotics/docs/module4/outline"}}');var n=i(4848),s=i(8453);const a={sidebar_position:2},r="Module 4 Exercises",l={},c=[{value:"Exercise 1: Using an LLM API to generate robot commands",id:"exercise-1-using-an-llm-api-to-generate-robot-commands",level:2},{value:"Exercise 2: Building a simple text-based interface to control a simulated robot",id:"exercise-2-building-a-simple-text-based-interface-to-control-a-simulated-robot",level:2},{value:"Exercise 3: Integrating a simple VLA model",id:"exercise-3-integrating-a-simple-vla-model",level:2},{value:"Exercise 4: Exploring the limitations and biases of LLMs in a robotics context",id:"exercise-4-exploring-the-limitations-and-biases-of-llms-in-a-robotics-context",level:2}];function d(e){const t={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"module-4-exercises",children:"Module 4 Exercises"})}),"\n",(0,n.jsx)(t.p,{children:'These exercises are designed to accompany Module 4 of the "Physical AI & Humanoid Robotics" textbook.'}),"\n",(0,n.jsx)(t.h2,{id:"exercise-1-using-an-llm-api-to-generate-robot-commands",children:"Exercise 1: Using an LLM API to generate robot commands"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Sign up for an API key from an LLM provider (e.g., OpenAI)."}),"\n",(0,n.jsx)(t.li,{children:"Write a Python script that takes a natural language command as input and uses the LLM API to generate a sequence of robot commands."}),"\n",(0,n.jsxs)(t.li,{children:['For example, if the input is "go to the kitchen", the output could be ',(0,n.jsx)(t.code,{children:"[\"go_to('kitchen')\"]"}),"."]}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"exercise-2-building-a-simple-text-based-interface-to-control-a-simulated-robot",children:"Exercise 2: Building a simple text-based interface to control a simulated robot"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Create a new ROS 2 Python node that takes text input from the user."}),"\n",(0,n.jsx)(t.li,{children:"In this node, use the script from Exercise 1 to convert the text input into a robot command."}),"\n",(0,n.jsx)(t.li,{children:"Publish the robot command to a ROS 2 topic."}),"\n",(0,n.jsx)(t.li,{children:"Create another ROS 2 node that subscribes to the topic and controls a simulated robot in Gazebo or Isaac Sim."}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"exercise-3-integrating-a-simple-vla-model",children:"Exercise 3: Integrating a simple VLA model"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Find a pre-trained VLA model that is suitable for a simple robotics task, such as pick-and-place."}),"\n",(0,n.jsx)(t.li,{children:"Write a ROS 2 node that uses the VLA model to generate a robot command from an image and a text prompt."}),"\n",(0,n.jsx)(t.li,{children:'For example, you could give the model an image of a table with several objects on it and the prompt "pick up the red ball".'}),"\n"]}),"\n",(0,n.jsx)(t.h2,{id:"exercise-4-exploring-the-limitations-and-biases-of-llms-in-a-robotics-context",children:"Exercise 4: Exploring the limitations and biases of LLMs in a robotics context"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Design an experiment to test the limitations of an LLM for a robotics task."}),"\n",(0,n.jsx)(t.li,{children:"For example, you could try giving the LLM ambiguous or nonsensical commands and see how it responds."}),"\n",(0,n.jsx)(t.li,{children:"Write a short report on your findings, including a discussion of the potential biases of LLMs in robotics."}),"\n"]})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},8453:(e,t,i)=>{i.d(t,{R:()=>a,x:()=>r});var o=i(6540);const n={},s=o.createContext(n);function a(e){const t=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),o.createElement(s.Provider,{value:t},e.children)}}}]);